#!/bin/bash

echo "ğŸ‡»ğŸ‡³ Setting up PhoBERT for Vietnamese Traffic QA..."

# 1. Install dependencies
echo "ğŸ“¦ Installing dependencies..."
pip install transformers==4.30.0 sentencepiece protobuf

# 2. Download PhoBERT (sáº½ cache local)
echo "â¬‡ï¸ Downloading PhoBERT..."
python -c "
from transformers import AutoModel, AutoTokenizer
print('Downloading PhoBERT-base...')
tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')
model = AutoModel.from_pretrained('vinai/phobert-base')
print(f'âœ… Downloaded: vocab_size={len(tokenizer)}, hidden_size={model.config.hidden_size}')
"

# 3. Test tokenization
echo "ğŸ§ª Testing PhoBERT tokenization..."
python -c "
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base', use_fast=False)

test_text = 'Xe Ã´ tÃ´ cÃ³ Ä‘Æ°á»£c phÃ©p ráº½ trÃ¡i khÃ´ng?'
tokens = tokenizer.tokenize(test_text)
ids = tokenizer.encode(test_text)

print(f'Input: {test_text}')
print(f'Tokens: {tokens}')
print(f'Token IDs: {ids}')
print(f'Decoded: {tokenizer.decode(ids)}')
"

echo "âœ… PhoBERT setup completed!"