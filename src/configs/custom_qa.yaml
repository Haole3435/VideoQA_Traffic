# Config cho PhoBERT Vietnamese QA
stage: 2
qa_type: 'multichoice'


sample_clip: 1
max_text_len: 256
num_choices: 4
# === BERT CONFIG - PHOBERT ===
bert_config: '/mnt/VideoQA_Traffic/LF-VILA/src/configs/phobert_base_config.json'  # ← ĐỔI TỪ bert_large_config.json
type_vocab_size: 1  # ← PhoBERT dùng 1 thay vì 2
num_local_layers: 6
stage1_layers: 2
bert_frozen_stage: -1  # Không freeze, để học tiếng Việt
final_num_patches: 96

# === VIDEO SETTINGS ===
DATA:
  input_res: [256, 256]
  center_crop: 256
  num_frames: 16
  sample_frame: 16
  sample_clip: 1
  max_text_len: 256
  num_choices: 4
  classification_labels: 4
  
  BATCH_SIZE_per_gpu: 1
  NUM_WORKERS: 4
  PIN_MEMORY: true
  
  DATASET_train:
    - name: 'OCRDataset-train'
      type: 'CustomOCRDataset'
      metadata_file: '/mnt/VideoQA_Traffic/LF-VILA/data/train/train.json'
      video_dir: '/mnt/VideoQA_Traffic/LF-VILA/data/train/videos'
  
  DATASET_val:
    - name: 'OCRDataset-val'
      type: 'CustomOCRDataset'
      metadata_file: '/mnt/VideoQA_Traffic/LF-VILA/data/train/val.json'
      video_dir: '/mnt/VideoQA_Traffic/LF-VILA/data/train/videos'

# === VIDEO ENCODER ===
VideoEncoder:
  pretrained: null
  pretrained2d: true
  patch_size: [1, 8, 8]
  in_chans: 3
  embed_dim: 128
  depths: [2, 2, 14, 2, 2, 2]
  num_heads: [4, 8, 16, 16, 16, 32]
  stages: [0, 1, 2, 2, 2, 3]
  downsample_stages: [0, 1, 4]
  window_size: [[2,3,5],[4,3,5],[8,3,5],[8,3,5],[8,3,5],[16,3,5]]
  mlp_ratio: 4.0
  drop_path_rate: 0.3

# === WEIGHTS - PHOBERT ===
WEIGHTS:
  # QUAN TRỌNG: Để trống, PhoBERT sẽ tự động load từ HuggingFace
  model_weight: ''
  bert_weight: ''  # ← Để TRỐNG, không dùng bert-large-uncased
  swin_weight: '/mnt/VideoQA_Traffic/LF-VILA/checkpoint/lfvila_release/pretrained/swin/swin_base_patch4_window12_384_22k.pth'
  stage1_model_weight: ''
  pretrained_2d: true

# === TRAINING ===
use_simple_merge_qas: true

TRAINING:
  num_train_epochs: 50
  EPOCHS: 50
  save_dir: 'output/videoqa_vietnamese_phobert'
  log_period: 10
  print_step: 10
  val_period: 80
  checkpoint_step: 80
  eval_step: 80
  save_step: 80
  gradient_accumulation_steps: 16
  save_latest: true
  use_mlm: false
  use_span_loss: false        # Tắt tính năng dự đoán span thời gian
  span_loss_weight: 0.0
  
  weight_decay: 0.05
  WARMUP_EPOCHS: 2
  WARMUP_LR: 1.0e-6
  MIN_LR: 1.0e-7
  
  LR_SCHEDULER:
    NAME: 'cosine'
    DECAY_EPOCHS: 15
    DECAY_RATE: 0.1

# === OPTIMIZER ===
OPTIMIZER:
  name: 'adamw'
  lr: 1.0e-5  # PhoBERT base tốt với 5e-5
  weight_decay: 0.05
  betas: [0.9, 0.999]
  eps: 1.0e-8

# === DEEPSPEED ===
deepspeed_config:
  train_batch_size: 16
  train_micro_batch_size_per_gpu: 1
  gradient_accumulation_steps: 16
  
  optimizer:
    type: 'AdamW'
    params:
      lr: 1.0e-5
      weight_decay: 0.05
      betas: [0.9, 0.999]
  
  scheduler:
    type: 'WarmupDecayLR'
    params:
      warmup_min_lr: 1.0e-6
      warmup_max_lr: 1.0e-5
      warmup_num_steps: 1000
      total_num_steps: 50000
  
  fp16:
    enabled: false
    loss_scale: 0
    loss_scale_window: 1000
    hysteresis: 2
    min_loss_scale: 1
  
  gradient_clipping: 1.0
  
  zero_optimization:
    stage: 1
    offload_optimizer:
      device: 'cpu'
      pin_memory: true