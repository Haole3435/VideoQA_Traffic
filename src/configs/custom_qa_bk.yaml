# custom_qa_3090.yaml
# File config cho máy 3090 (24GB VRAM) - Train bằng Kịch bản A

inherit_from: "/mnt/XPretrain/LF-VILA/src/configs/violin_qa.yaml"
qa_type: 'classification'
# --- Tùy chỉnh cho dataset của bạn ---
dataset_name: "custom_qa"
VideoEncoder: {
    "patch_size": [1,8,8],
    "embed_dim": 128,
    "depths": [2, 2, 14, 2, 2, 2],
    "downsample_stages": [0, 1, 4],
    "stages": [0, 1, 2, 2, 2, 3],
    "num_heads": [4, 8, 16, 16, 16, 32],
    "window_size": [[2,3,5],[4,3,5],[8,3,5],[16,3,5],[16,3,5],[32,3,5]],
    "patch_norm": True,
    "local_window": 8
}
bert_config: "/mnt/XPretrain/LF-VILA/src/configs/bert_large_config.json"
stage: 2
type_vocab_size: 8
num_local_layers: 8
stage1_layers: 12
bert_frozen_stage: -1
final_num_patches: 6

WEIGHTS:
    model_weight: '/mnt/XPretrain/LF-VILA/checkpoint/lfvila_release/lfvila_release/pretrained/lfvila_stage2_release.bin'
    stage1_model_weight: ''
    bert_weight: '/mnt/XPretrain/LF-VILA/checkpoint/lfvila_release/lfvila_release/pretrained/bert-large-uncased/pytorch_model.bin'
    swin_weight: '/mnt/XPretrain/LF-VILA/checkpoint/lfvila_release/lfvila_release/pretrained/swin/swin_base_patch4_window12_384_22k.pth'
    pretrained_2d: True

DATA:
    BATCH_SIZE_per_gpu: 4
    NUM_WORKERS: 12
    PIN_MEMORY: True

    sample_frame: 32
    sample_clip: 4
    input_res: [192, 320]
    center_crop: 200


    classification_labels: 4
    DATASET_train: {
        'name': 'OCRDataset-train',
        'type': 'CustomOCRDataset',
        'metadata_file': 'data/ocr_data/train_ocr.json',
        'video_dir': 'data/train'
    }

    DATASET_val: [{
        'name': 'OCRDataset-val',
        'type': 'CustomOCRDataset',
        'metadata_file': 'data/ocr_data/public_test_ocr.json',
        'video_dir': 'data/train'
    }]

# --- Training ---
TRAINING:
    EPOCHS: 100
    WARMUP_EPOCHS: 10
    WARMUP_LR: 0.0
    MIN_LR: 1.0e-8
    LR_SCHEDULER: {
        'NAME': 'cosine',
        'DECAY_EPOCHS': 10
    }
    use_mlm: false
    weight_decay: 0.1
    save_dir: "/mnt/XPretrain/LF-VILA/final_checkpoint"
    checkpoint_step: 10000
    save_step: 5000
    print_step: 100
    eval_step: 500

# --- TÙY CHỈNH TỐI ƯU CHO 3090 (24GB VRAM) ---
num_frames: 32 
max_text_len: 128

# Cài đặt Batch Size (batch_size: [train, val])
# 24GB VRAM có thể chạy batch size lớn hơn nhiều
batch_size: [8, 8] 

# Tích lũy Gradient
# (batch_size * gradient_accumulation_steps) = batch_size hiệu quả
# 8 * 4 = 32
gradient_accumulation_steps: 4

# Tối ưu Dataloader
# Máy của bạn có 16 cores, đặt num_workers cao lên!
# Vì Dataloader (Kịch bản A) rất nhẹ, nó sẽ chạy nhanh.
num_workers: 8



deepspeed_config: {
    "train_micro_batch_size_per_gpu": 4,
    "gradient_accumulation_steps": 8,
    "steps_per_print": 500,


    "zero_optimization": {
      "stage": 2,
      "allgather_partitions": true,
      "allgather_bucket_size": 5.0e+8,
      "overlap_comm": false,
      "reduce_scatter": true,
      "reduce_bucket_size": 5.0e+8,
      "contiguous_gradients" : false,
      "stage3_gather_fp16_weights_on_model_save": true
    },

    "fp16": {
      "enabled": true,
      "loss_scale": 0,
      "loss_scale_window": 1000,
      "initial_scale_power": 32,
      "hysteresis": 2,
      "min_loss_scale": 1
  },

    "optimizer": {
        "type": "AdamW",
        "params": {
        "lr": 5.0e-5,
        "betas": [0.9, 0.98],
        "eps": 1.0e-8,
        "weight_decay": 5.0e-2
        }
    },


    "sparse_attention": {
      "mode": "fixed",
      "block": 32,
      "different_layout_per_head": true,
      "num_local_blocks": 16,
      "num_global_blocks": 1,
      "attention": "bidirectional",
      "horizontal_global_attention": true,
      "num_different_global_patterns": 4
    }
}


